---
title: "A Self-Attentional Neural Architecture for Code Completion with Multi-Task Learning"
collection: publications
permalink: /publication/MTL
excerpt: 'This paper built a multi-task learning model for source code modeling and code completion, which predicted next node's type and value jointly. Adopt Transformer-XL network as the base model and consider the path from the predicting node to the root node.'
date: 2020-10-01
venue: 'International Conference on Program Comprehension (ICPC, **ACM Distinguished Paper Award**)'
paperurl: 'https://arxiv.org/abs/1909.06983'
citation: 'Liu, F. (2020). &quot;A Self-Attentional Neural Architecture for Code Completion with Multi-Task Learning.&quot; <i>International Conference on Program Comprehension, 2020</i>.'
---



