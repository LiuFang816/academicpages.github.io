---
title: "A Self-Attentional Neural Architecture for Code Completion"
collection: publications
permalink: /publication/MTL
excerpt: "This paper built a multi-task learning model for source code modeling and code completion, which predicts next node's type and value jointly. Employed Transformer-XL network as the base model and consider the path from the predicting node to the root node."
date: 2020-10-01
venue: 'International Conference on Program Comprehension (ICPC, **ACM Distinguished Paper Award**)'
paperurl: 'https://arxiv.org/pdf/1909.06983.pdf'
citation: 'Liu, F. (2020). &quot;A Self-Attentional Neural Architecture for Code Completion.&quot; <i>International Conference on Program Comprehension. 2020</i>.'
---

